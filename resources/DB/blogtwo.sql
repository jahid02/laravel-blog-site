-- phpMyAdmin SQL Dump
-- version 4.8.5
-- https://www.phpmyadmin.net/
--
-- Host: 127.0.0.1
-- Generation Time: Nov 09, 2019 at 03:37 PM
-- Server version: 10.1.40-MariaDB
-- PHP Version: 7.3.5

SET SQL_MODE = "NO_AUTO_VALUE_ON_ZERO";
SET AUTOCOMMIT = 0;
START TRANSACTION;
SET time_zone = "+00:00";


/*!40101 SET @OLD_CHARACTER_SET_CLIENT=@@CHARACTER_SET_CLIENT */;
/*!40101 SET @OLD_CHARACTER_SET_RESULTS=@@CHARACTER_SET_RESULTS */;
/*!40101 SET @OLD_COLLATION_CONNECTION=@@COLLATION_CONNECTION */;
/*!40101 SET NAMES utf8mb4 */;

--
-- Database: `blogtwo`
--

-- --------------------------------------------------------

--
-- Table structure for table `authors`
--

CREATE TABLE `authors` (
  `id` bigint(20) UNSIGNED NOT NULL,
  `name` varchar(191) COLLATE utf8mb4_unicode_ci NOT NULL,
  `phone` varchar(15) COLLATE utf8mb4_unicode_ci NOT NULL,
  `description` text COLLATE utf8mb4_unicode_ci NOT NULL,
  `status` enum('Active','Inactive') COLLATE utf8mb4_unicode_ci NOT NULL,
  `created_at` timestamp NULL DEFAULT NULL,
  `updated_at` timestamp NULL DEFAULT NULL
) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COLLATE=utf8mb4_unicode_ci;

--
-- Dumping data for table `authors`
--

INSERT INTO `authors` (`id`, `name`, `phone`, `description`, `status`, `created_at`, `updated_at`) VALUES
(3, 'Jahid Hassan', '01745998860', 'Web Application Developer in Laravel framework', 'Active', '2019-07-25 07:49:10', '2019-07-27 13:05:23');

-- --------------------------------------------------------

--
-- Table structure for table `categories`
--

CREATE TABLE `categories` (
  `id` bigint(20) UNSIGNED NOT NULL,
  `name` varchar(191) COLLATE utf8mb4_unicode_ci NOT NULL,
  `status` enum('Active','Inactive') COLLATE utf8mb4_unicode_ci NOT NULL,
  `created_at` timestamp NULL DEFAULT NULL,
  `updated_at` timestamp NULL DEFAULT NULL
) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COLLATE=utf8mb4_unicode_ci;

--
-- Dumping data for table `categories`
--

INSERT INTO `categories` (`id`, `name`, `status`, `created_at`, `updated_at`) VALUES
(9, 'Internet', 'Inactive', '2019-07-25 01:01:34', '2019-07-27 12:37:37'),
(10, 'Robotics', 'Active', '2019-07-25 07:21:58', '2019-07-26 13:12:06'),
(11, 'Artificial intelligence', 'Active', '2019-07-27 00:54:06', '2019-07-27 00:54:06'),
(12, 'Computer', 'Active', '2019-07-27 12:12:26', '2019-07-27 12:12:26'),
(13, 'Others', 'Active', '2019-07-27 12:38:09', '2019-07-27 12:38:09'),
(15, 'Mobile Phone', 'Active', '2019-08-19 08:37:03', '2019-08-19 08:37:03');

-- --------------------------------------------------------

--
-- Table structure for table `migrations`
--

CREATE TABLE `migrations` (
  `id` int(10) UNSIGNED NOT NULL,
  `migration` varchar(191) COLLATE utf8mb4_unicode_ci NOT NULL,
  `batch` int(11) NOT NULL
) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COLLATE=utf8mb4_unicode_ci;

--
-- Dumping data for table `migrations`
--

INSERT INTO `migrations` (`id`, `migration`, `batch`) VALUES
(1, '2014_10_12_000000_create_users_table', 1),
(2, '2014_10_12_100000_create_password_resets_table', 1),
(3, '2019_07_23_120549_create_categories_table', 1),
(4, '2019_07_25_060657_create_posts_table', 2),
(5, '2019_07_25_121306_create_authors_table', 3),
(6, '2019_07_25_122115_add_new_field_in_post_table', 3),
(7, '2019_07_25_123548_add_new_field_in_post_table', 4);

-- --------------------------------------------------------

--
-- Table structure for table `password_resets`
--

CREATE TABLE `password_resets` (
  `email` varchar(191) COLLATE utf8mb4_unicode_ci NOT NULL,
  `token` varchar(191) COLLATE utf8mb4_unicode_ci NOT NULL,
  `created_at` timestamp NULL DEFAULT NULL
) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COLLATE=utf8mb4_unicode_ci;

-- --------------------------------------------------------

--
-- Table structure for table `posts`
--

CREATE TABLE `posts` (
  `id` bigint(20) UNSIGNED NOT NULL,
  `category_id` int(11) NOT NULL,
  `title` varchar(191) COLLATE utf8mb4_unicode_ci NOT NULL,
  `short_description` text COLLATE utf8mb4_unicode_ci NOT NULL,
  `description` longtext COLLATE utf8mb4_unicode_ci NOT NULL,
  `image` text COLLATE utf8mb4_unicode_ci NOT NULL,
  `is_featured` enum('Yes','No') COLLATE utf8mb4_unicode_ci NOT NULL DEFAULT 'No',
  `total_hit` int(11) DEFAULT '0',
  `published_date` date NOT NULL,
  `status` enum('Published','Unpublished') COLLATE utf8mb4_unicode_ci NOT NULL,
  `created_at` timestamp NULL DEFAULT NULL,
  `updated_at` timestamp NULL DEFAULT NULL,
  `author_id` int(11) DEFAULT NULL
) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COLLATE=utf8mb4_unicode_ci;

--
-- Dumping data for table `posts`
--

INSERT INTO `posts` (`id`, `category_id`, `title`, `short_description`, `description`, `image`, `is_featured`, `total_hit`, `published_date`, `status`, `created_at`, `updated_at`, `author_id`) VALUES
(7, 11, 'Artificial intelligence thinks your face is full of data. Could it actually unmask you?', 'Why humans, and by extension our machines, are so determined to “read” people.', 'Each January, some 4,500 companies descend upon Las Vegas for the psychological marathon known as the Consumer Electronics Show, or CES.\r\n\r\nThe 2019 festivities were much like any other. Companies oversold their ideas. Attendees tweeted out the craziest products, and Instagrammed the endless miles of convention space. Trend-spotting was the name of the game, and this year\'s trends ran the gamut: drones, voice-activated home assistants, something called \"8K\" television. But the most provocative robots were those that claimed to \"read\" humans faces, revealing our emotions and physical health in a single image.\r\n\r\nSome were overwhelming if toothless mashups of meme culture and pseudoscience. One machine interpreted a photo of our 36-year-old technology editor, Stan Horaczek, as \"adorable, age 30, and looks like a G-Dragon.\" (Two of three isn\'t bad.) Another determined he was like age 47 and \"male 98 percent.\" Both featured many, many emoji.\r\n\r\nBut some of the proposals could have profound consequences for our everyday lives. Intel offered an update on its effort to build a wheelchair controlled by facial expressions (turn left with a wink, or right with a kissy-face), which would have clear and positive implications for mobility. Veoneer promoted its \"expression recognition\" concept for autonomous vehicle AI. It will judge facial expressions to determine if drivers are engaged, sleepy, or otherwise distracted on the road. And still others expressed an intention to automate part of a doctor\'s visit, peering deep into our faces to determine what ails us.\r\n\r\nADVERTISEMENT / ADVERTISE WITH US\r\nThe wares on display at CES may be shiny and new, but the human desire to turn faces into information has its origins in antiquity. The Greek mathematician Pythagoras selected his students \"based on how gifted they looked,\" according to Sarah Waldorf of the J. Paul Getty Trust. In the 1400s, the vermillion birthmark on the face of James II of Scotland (alias: \"Fiery Face\") was considered an outward manifestation of his smouldering temper. And in colonial Europe, many scientists lent credibility to racist caricatures, which linked human expressions to animal behavior.\r\n\r\n\"Physiognomy,\" the name for the widely-held belief that our faces are wrinkled with ulterior meaning, has never really gone away. In The New York Times Magazine, Teju Cole argued that the belief manifests itself in every work of photography: \"We tend to interpret portraits as though we were reading something inherent in the person portrayed,\" he writes. \"We talk about strength and uncertainty; we praise people for their strong jaws and pity them their weak chins. High foreheads are deemed intelligent. We easily link the people\'s facial features to the content of their character.\"\r\n\r\nBut what can two eyes, a mouth, and a nose actually tell us?', 'images/post/artificialintelegent3.jpeg', 'Yes', 1, '2019-07-27', 'Published', '2019-07-27 00:55:58', '2019-08-19 07:43:25', 3),
(8, 11, 'Artificial intelligence made this robot dog a very good boy', 'The robot\'s \"brain\" actually learned in a simulator.', 'Meet ANYmal—a four-legged robot whose name is pronounced “animal.” The 73-pound dog-like machine is a Swiss-made contraption that, thanks to artificial intelligence, can run faster, operate with more efficiency, and reset itself after a spill more successfully than it could before its AI training.\r\n\r\nThe robot, featured in a new study in the journal Science Robotics, learned not just with AI, but also through computer simulation on a desktop, a much faster approach than teaching a robotic new tricks in the real, physical world. In fact, simulation is roughly 1,000-times faster than the real world, according to the study.\r\n\r\nThis isn\'t the only arena for which simulation is important: In the world of self-driving cars, time in simulation is a crucial way that companies test and refine the software that operates the vehicles. In this case, the researchers used a similar strategy, just with a robot dog.\r\n\r\nTo ensure that the simulator in which the virtual dog learned its skills was accurate, the researchers first made sure to incorporate data about how the robot behaves in the real world. Then, in simulation, a neural network—a type of machine learning tool—learned how to control the robot.\r\n\r\nADVERTISEMENT / ADVERTISE WITH US\r\nBesides the speed benefits of simulation, the technique allowed the researchers to do things to the robot that they wouldn’t want to do in real life. For example, they could virtually throw the breakable robo-dog in the air in the simulation, says Jemin Hwangbo, the lead researcher on the project and a postdoctoral fellow at the Robotic Systems Lab in Zurich, Switzerland. Then the pup could figure out how to stand back up after it landed.\r\n\r\nAfter the neural network had finished its training in simulation, the team was able to deploy that learning onto the physical robot itself—which stands over 2 feet tall, has 12 joints, is electrically-powered, and looks similar to a robot called SpotMini made by Boston Dynamics.\r\n\r\nThe final result, after the sim time and AI, was that the robo pooch could follow instructions more precisely—for example, if commanded to walk at 1.1 mph, it could do that more precisely than before, according to Hwangbo; it also was able to get up successfully after a fall, and run faster. Programming a complex robot like ANYmal with specific instructions on how to get up after a fall is complicated, while letting it learn how to do it in simulation is a much more robust approach.\r\n\r\nADVERTISEMENT / ADVERTISE WITH US\r\nChris Atkeson, a professor in both the Robotics Institute and Human-Computer Interaction Institute at Carnegie Mellon University, said that the method that Hwangbo and his team used is a time- and money-saver when it comes to getting a robot to do what you want it to do.\r\n\r\n“They made robot programming cheaper,” he says. “Programming is very expensive, and robot programming is really expensive, because you basically have to have robot whisperers.” That’s because the people who program robots need to be both good at coding, and good at making the robot’s mechanics perform properly.\r\n\r\nBut with Hwangbo and his team, their robot was able to learn in simulation, as opposed to programers carefully coding each action. It’s “a big step towards automating that kind of stuff,” Atkeson says.', 'images/post/artificialintelegent4.jpeg', 'Yes', 0, '2019-07-27', 'Published', '2019-07-27 00:57:50', '2019-07-27 00:57:50', 3),
(9, 10, 'This Video of a Robot Beating Up Humans Is Extremely Satisfying', 'The Boston Dynamics parody is seriously impressive ... and perhaps a bit ominous.', 'By now you’ve probably watched a few (dozen) videos from Boston Dynamics, the robotics company that makes its bones on developing bots that can do wildly impressive things. Hell, you’ve probably seen the firm’s viral videos posted on our page. Every few months, the Massachusetts-based maker releases clips of its creations stacking boxes and busting out backflips, and the Internet reacts accordingly.\r\n\r\nThese jaw-dropping demonstrations have long been ripe for parody, and now we finally get the Boston Dynamics send-up we deserve, court\r\n\r\nBy now you’ve probably watched a few (dozen) videos from Boston Dynamics, the robotics company that makes its bones on developing bots that can do wildly impressive things. Hell, you’ve probably seen the firm’s viral videos posted on our page. Every few months, the Massachusetts-based maker releases clips of its creations stacking boxes and busting out backflips, and the Internet reacts accordingly.\r\n\r\nThese jaw-dropping demonstrations have long been ripe for parody, and now we finally get the Boston Dynamics send-up we deserve, court', 'images/post/robotics.jpg', 'Yes', 6, '2019-07-27', 'Published', '2019-07-27 01:12:02', '2019-07-27 13:01:13', 3),
(10, 12, 'Upcoming Windows 10 1909: Update or upgrade? Microsoft clarifies', 'The next version of Windows 10, due out this fall, will continue to offer Windows Update for Business controls, the company says.', 'Microsoft this week clarified how the unprecedented Windows 10 refresh expected to ship in September will behave when users decide to skip installing it or want to postpone its appearance on their PCs.\r\n\r\n\"Customers can control 19H2 like other Feature Updates,\" a Microsoft spokesperson said in an email. \"For [Windows 10] Home and [Windows 10] Pro users, control will also remain unchanged and largely up to the user when to initiate when the update occurs.\"\r\n\r\n[ Related: Windows 7 to Windows 10 migration guide ]\r\nMicrosoft has code-named the fall release as 19H2 for now - the label identifying the upgrade as the second of the year - but it will likely be later named 1909 in the company\'s four-digit yymm format.\r\n\r\n \r\nOn the business front, where users and IT administrators historically have had much more control over incoming code, the refresh will also hew to the rules of a twice-annual feature upgrade.\r\n\r\n\"Windows Update for Business (WUfB) controls will be unchanged with 1909,\" Microsoft said. \"19H2 will be treated in the same fashion as previous Feature Updates.\"\r\n\r\nMary Jo Foley of ZDNet first reported on the it\'s-still-a-feature-upgrade nature of 19H2/1909 Monday.\r\n\r\nQuestions about the fall\'s feature upgrade arose because Microsoft made much about how the refresh would be strikingly different from past examples. \"We will deliver this feature update in a new way, using servicing technology (like the monthly update process),\" John Cable, director of program management for the Windows servicing and delivery team, wrote in a July 1 post to a company blog.\r\n\r\n[ Got a spare hour? Take this online course and learn how to install and configure Windows 10 with the options you need. ]\r\nHow Microsoft characterized 1909 and how it plans to distribute the upgrade are important to customers, especially to the people responsible for deploying updates and upgrades within their companies or organizations. Terms matter, even if Microsoft sometimes blurs the lines, intentionally or not.\r\n\r\nA feature upgrade, for example, can be deferred for up to 365 days by those running Windows 10 Pro and serviced through WUfB, and delayed even longer - although not indefinitely - on Windows 10 Home simply by not selecting the \"Download and install now\" (DaIN) option. (Windows 10 Enterprise-powered PCs are almost exclusively managed by IT administrators using WSUS (Windows Server Update Services) and other servicing platforms.) Monthly updates deployed through Windows Update and WUfB, however, can be paused only for a maximum of 35 days, in 7-day increments.\r\n\r\nElsewhere and as Microsoft issued a second preview of 19H2/1909 to Windows Insider participants who had assigned their devices to the \"Slow\" ring, the company repeated an explanation of how it will treat new features in the upgrade.\r\n\r\n\"Note that these changes and improvements are currently OFF by default in this build,\" said Dona Sarkar and Brandon LeBlanc, the two Microsoft employees who customarily blog about new Insider releases. \"As mentioned previously, we may ship features in these updates turned off by default and turn them on via controlled feature rollouts. With today\'s 19H2 build, we are testing this experience.\"\r\n\r\nEarlier, Microsoft said it was using this approach - one similar to that of browser makers including Google and Mozilla - to test the new feature or enhancements with progressively larger groups, so that if a bug slipped through it wouldn\'t affect everyone.\r\n\r\nSarkar and LeBlanc confirmed that in their post. \"Our plan is to quickly follow-up with another 19H2 build that turns these features on for a subset of Insiders and proceed from there based on feedback and quality.\"', 'images/post/computer3.jpg', 'No', 0, '2019-07-28', 'Published', '2019-07-27 12:20:38', '2019-07-27 12:20:38', 3),
(11, 12, 'macOS 10.14 Mojave release date, news and features', 'Everything you need to know about macOS Mojave', 'Now that macOS Mojave has been on our Macs, bringing key iOS apps like News and Stocks to the fold, Apple’s OS is better than ever before. But, that’s not all: Mojave is also stocked with fantastic new and improved features, like the system-wide Dark Mode and increased productivity through Finder.\r\n\r\nMACOS NEWS\r\nGoodbye, iTunes. Hello, Apple Music, Apple TV and Apple Podcasts.\r\n\r\nApple unveils the new, completely redesigned Mac Pro.\r\n\r\nIn the coming years, more iOS apps should be coming to the best Macs. Apple confirmed this at WWDC 2019 with Project Catalyst, which makes it easier and more seamless for developers to bring their iPhone and iPad apps to mac. Moreover, Project Catalyst has been available to developers as of June 3 with the beta version of macOS Catalina, so we can expect app developers to be releasing more macOS versions of iOS apps soon.\r\n\r\nRECOMMENDED VIDEOS FOR YOU...\r\n\r\nvideo playingWindows 8.1 release date, news and features\r\nIPhone 5S revealed: Release date, price,...\r\n10/09/13IPhone 5S revealed: Release date, price, specs & features\r\nXbox 720 Release Date, Concepts, News and...\r\n22/03/13Xbox 720 Release Date, Concepts, News and Rumours\r\nIPad 4: Review of release date, price, specs &...\r\n24/10/12IPad 4: Review of release date, price, specs & features\r\nWindows Phone 8 Apollo Rumours (Nokia Lumia) ...\r\n16/02/12Windows Phone 8 Apollo Rumours (Nokia Lumia) - Specs, features, release date\r\nIPhone 8 rumors, release date and predictions\r\n16/03/17IPhone 8 rumors, release date and predictions\r\nYet even now, there’s already a lot to love in macOS 10.14. And, despite macOS Mojave having its own fair share of security issues, most notably KeySteal, the operating system is on the whole safe and secure. \r\n\r\nApple’s macOS Mojave has been on our Macs for more than eight months at this point and most, if not all, of the problems have been addressed. Plus, any problems that do remain are dwarfed by the benefits this new OS brings to the table. \r\n\r\nLet’s dive into all of its benefits, alongside any new features that have been added, so you can decide for yourself whether or not the upgrade is for you.\r\n\r\nMake the most out of the new operating system with the best macOS 10.14 Mojave tips and tricks\r\nInstalled Mojave and having issues? Check out our guide on macOS 10.14 Mojave problems: how to fix them\r\nCut to the chase\r\nWhat is it? The 2018 edition of Apple’s Mac operating system, macOS\r\nWhen is it out? macOS Mojave is out right now\r\nWhat will it cost? macOS 10.14 is free\r\nmacos mojave\r\n\r\nmacOS 10.14 Mojave release date\r\nHOW TO DOWNLOAD\r\nLearn how to download and install macOS 10.14 Mojave right here.\r\n\r\nApple unveiled macOS Mojave back in June 2018 at WWDC 2018, where most of its features were highlighted. This was followed by a public beta launch back in July, and finally a full launch on September 24, 2018.\r\n\r\nApple has been keeping macOS Mojave updated with all the latest features. The latest of these updates, macOS 10.14.4, brings Dark Mode to Safari, alongside the new Apple News+ service. Past updates included a fix for the FaceTime Bug, which allowed other people to access your camera without you answering their call, and a supplemental update to boost reliability for the 2018 MacBook Air.\r\n\r\nApple has also released macOS 10.14.5, which will likely be one of the last major updates to the operating system before macOS 10.15 is unveiled. This update focuses on stability, and is still very much worth downloading despite its more nuanced refinements.\r\n\r\nStay tuned here as well, as we will', 'images/post/computer4.jpg', 'No', 1, '2019-07-28', 'Published', '2019-07-27 12:25:46', '2019-07-27 13:02:36', 3),
(12, 12, 'Apple\'s 16-inch MacBook Pro to end the era of Butterfly keyboards', 'No more butterflies in Apple\'s stomach', 'Apple has a new, 16-inch MacBook Pro expected to launch later this year, and a new report from Apple analyst Ming-Chi Kuo suggests it may be the first model to switch away from the Butterfly switch keyboards found in all MacBooks for the past few years, 9to5Mac reports.\r\n\r\nThe Butterfly keyboards used in MacBook, MacBook Air and MacBook Pro models have been plagued with issues since they first showed up. While the Butterfly key switch mechanism allowed Apple to make extra thin keyboards, they have suffered issues with debris getting underneath them, sticking keys, and missed and repeat key presses. \r\n\r\nRECOMMENDED VIDEOS FOR YOU...\r\n\r\nvideo playingRetina MacBook Pro 2012 vs 2011 Build Comparison - side by side\r\nVideo Highlights : TechRadar Mobile...\r\n05/06/19Video Highlights : TechRadar Mobile Choice Consumer Awards 2018\r\nHuawei Mate 20 and Mate 20 Pro hands-on\r\n17/10/18Huawei Mate 20 and Mate 20 Pro hands-on\r\nIPhone XS vs XS Max vs XR: What\'s the...\r\n13/09/18IPhone XS vs XS Max vs XR: What\'s the difference between Apple\'s new iPhones?\r\nApple Watch Series 4 explained\r\n12/09/18Apple Watch Series 4 explained\r\nAsus ZenBook Pro (2018) with ScreenPad hands...\r\n05/06/18Asus ZenBook Pro (2018) with ScreenPad hands-on review\r\nNone of these are experiences someone wants to have on a keyboard, especially one attached to a laptop that comes at a hefty premium. Apple addressed the issues in several ways, with improved Butterfly keyboards, and with a keyboard service program that covers all models with Butterfly keyboards. But, even with its latest release of MacBooks, Apple continues to use the Butterfly keyboards.\r\n\r\nSee how Intel may have an edge on AMD in mobile CPUs\r\nThese are the best AMD processors\r\nHere are the best laptops\r\nOut with the old, in with the older\r\nPreviously, Kuo had suggested that the new keyboards, which will use a common scissor switch mechanism, would come in 2020 MacBooks. And, while Kuo still somewhat stands behind that, the anticipated MacBook Pro accelerates the timeline somewhat.\r\n\r\nHis report still suggests that MacBooks released in 2020 will dump the Butterfly keyboard in favor of the new design using scissor switches.\r\n\r\nAll that is really changing to the timeline is that the rumored 16-inch MacBook Pro will come out sooner than the other models – October 2019, apparently – with the new scissor switch keyboard.\r\n\r\nThis is a plus for anyone who saw the previous report but h\r\n\r\n\r\nApple has a new, 16-inch MacBook Pro expected to launch later this year, and a new report from Apple analyst Ming-Chi Kuo suggests it may be the first model to switch away from the Butterfly switch keyboards found in all MacBooks for the past few years, 9to5Mac reports.\r\n\r\nThe Butterfly keyboards used in MacBook, MacBook Air and MacBook Pro models have been plagued with issues since they first showed up. While the Butterfly key switch mechanism allowed Apple to make extra thin keyboards, they have suffered issues with debris getting underneath them, sticking keys, and missed and repeat key presses. \r\n\r\nRECOMMENDED VIDEOS FOR YOU...\r\n\r\nvideo playingRetina MacBook Pro 2012 vs 2011 Build Comparison - side by side\r\nVideo Highlights : TechRadar Mobile...\r\n05/06/19Video Highlights : TechRadar Mobile Choice Consumer Awards 2018\r\nHuawei Mate 20 and Mate 20 Pro hands-on\r\n17/10/18Huawei Mate 20 and Mate 20 Pro hands-on\r\nIPhone XS vs XS Max vs XR: What\'s the...\r\n13/09/18IPhone XS vs XS Max vs XR: What\'s the difference between Apple\'s new iPhones?\r\nApple Watch Series 4 explained\r\n12/09/18Apple Watch Series 4 explained\r\nAsus ZenBook Pro (2018) with ScreenPad hands...\r\n05/06/18Asus ZenBook Pro (2018) with ScreenPad hands-on review\r\nNone of these are experiences someone wants to have on a keyboard, especially one attached to a laptop that comes at a hefty premium. Apple addressed the issues in several ways, with improved Butterfly keyboards, and with a keyboard service program that covers all models with Butterfly keyboards. But, even with its latest release of MacBooks, Apple continues to use the Butterfly keyboards.\r\n\r\nSee how Intel may have an edge on AMD in mobile CPUs\r\nThese are the best AMD processors\r\nHere are the best laptops\r\nOut with the old, in with the older\r\nPreviously, Kuo had suggested that the new keyboards, which will use a common scissor switch mechanism, would come in 2020 MacBooks. And, while Kuo still somewhat stands behind that, the anticipated MacBook Pro accelerates the timeline somewhat.\r\n\r\nHis report still suggests that MacBooks released in 2020 will dump the Butterfly keyboard in favor of the new design using scissor switches.\r\n\r\nAll that is really changing to the timeline is that the rumored 16-inch MacBook Pro will come out sooner than the other models – October 2019, apparently – with the new scissor switch keyboard.\r\n\r\nThis is a plus for anyone who saw the previous report but h', 'images/post/computer5.jpg', 'Yes', 0, '2019-07-28', 'Published', '2019-07-27 12:28:04', '2019-07-27 12:28:04', 3),
(13, 12, 'Ryzen Threadripper 3000 leak hints at how quick AMD’s next-gen CPUs will be', 'Along with a supposed sighting of 4th-generation Threadripper chips', 'A single leak regarding upcoming beefy Ryzen Threadripper processors not good enough for you? Well, perhaps two leaks will satisfy, then – we have potential details on 3rd-generation Threadripper chips from a leaked performance benchmark, plus an alleged sighting of 4th-generation Threadripper chips.\r\n\r\nSo let’s start with that 3rd-gen leak which concerns a CPU spotted in a UserBenchmark result by prolific Twitter leaker TUM_APISAK.\r\n\r\nGoing by the spec, this is seemingly one of AMD’s Threadripper 3000 (7nm) processors (codenamed Castle Peak), and it appears with 16-cores (32-threads), featuring a base clock of 3.6GHz and boost to 4.05GHz.\r\n\r\nIf you compare that to the current Ryzen Threadripper 2950X flagship, this current model has the same core count with a slightly slower base clock of 3.5GHz, but boosts to 4.4GHz.\r\n\r\nAMD Ryzen 9 3900X is the best mainstream CPU around\r\nAnd here’s the rest of the best AMD processors\r\nCheck out how to overclock your CPU\r\nIn terms of performance, the allegedly incoming Castle Peak chip eases past the 2950X to the tune of 11% in single-core and quad-core usage in UserBenchmark, and 18% faster in multi-core.\r\n\r\nAnd as Wccftech, which spotted this, further notes, it outperforms the Ryzen 9 3900X by 35% in multi-core performance.\r\n\r\nOf course, bear in mind that this leak concerns an alleged engineering sample, so even if the benchmark is real, it still doesn’t represent the finished product or the final clock speeds or performance levels. And, we can likely anticipate a considerably higher boost than 4.05GHz (certainly if the base clock is higher as shown).\r\n\r\nWe were previously expecting Threadripper 3000 products to turn up at some point in 2019, and they still might – although 2020 is looking more likely now, after the CPUs disappeared from AMD’s roadmap for this year (and given that the chip maker currently seems to be focused on mainstream Ryzen and Rome server processors).\r\n\r\nWhenever it turns up, the hope is that this 3rd-gen line-up will include a 64-core flagship.', 'images/post/computer6.jpg', 'No', 0, '2019-07-28', 'Published', '2019-07-27 12:35:46', '2019-07-27 12:35:46', 3),
(14, 10, 'New e-skin innovation gives robots and prosthetics an exceptional sense of touch', 'Robots and prosthetic devices may soon have a sense of touch equivalent to, or better than, the human skin with the Asynchronous Coded Electronic Skin (ACES)', 'Faster than the human sensory nervous system\r\n\r\n\"Humans use our sense of touch to accomplish almost every daily task, such as picking up a cup of coffee or making a handshake. Without it, we will even lose our sense of balance when walking. Similarly, robots need to have a sense of touch in order to interact better with humans, but robots today still cannot feel objects very well,\" explained Asst Prof Tee, who has been working on electronic skin technologies for over a decade in hope of giving robots and prosthetic devices a better sense of touch.\r\n\r\nDrawing inspiration from the human sensory nervous system, the NUS team spent a year and a half developing a sensor system that could potentially perform better. While the ACES electronic nervous system detects signals like the human sensor nervous system, it is made up of a network of sensors connected via a single electrical conductor, unlike the nerve bundles in the human skin. It is also unlike existing electronic skins which have interlinked wiring systems that can make them sensitive to damage and difficult to scale up.\r\n\r\nElaborating on the inspiration, Asst Prof Tee, who also holds appointments in the NUS Department of Electrical and Computer Engineering, NUS Institute for Health Innovation & Technology (iHealthTech), N.1 Institute for Health and the Hybrid Integrated Flexible Electronic Systems (HiFES) programme, said, \"The human sensory nervous system is extremely efficient, and it works all the time to the extent that we often take it for granted. It is also very robust to damage. Our sense of touch, for example, does not get affected when we suffer a cut. If we can mimic how our biological system works and make it even better, we can bring about tremendous advancements in the field of robotics where electronic skins are predominantly applied.\"\r\n\r\nACES can detect touches more than 1,000 times faster than the human sensory nervous system. For example, it is capable of differentiating physical contacts between different sensors in less than 60 nanoseconds -- the fastest ever achieved for an electronic skin technology -- even with large numbers of sensors. ACES-enabled skin can also accurately identify the shape, texture and hardness of objects within 10 milliseconds, ten times faster than the blinking of an eye. This is enabled by the high fidelity and capture speed of the ACES system.\r\n\r\nThe ACES platform can also be designed to achieve high robustness to physical damage, an important property for electronic skins because they come into the frequent physical contact with the environment. Unlike the current system used to interconnect sensors in existing electronic skins, all the sensors in ACES can be connected to a common electrical conductor with each sensor operating independently. This allows ACES-enabled electronic skins to continue functioning as long as there is one connection between the sensor and the conductor, making them less vulnerable to damage.\r\n\r\nSmart electronic skins for robots and prosthetics\r\n\r\nACES\' simple wiring system and remarkable responsiveness even with increasing numbers of sensors are key characteristics that will facilitate the scale-up of intelligent electronic skins for Artificial Intelligence (AI) applications in robots, prosthetic devices and other human machine interfaces.\r\n\r\n\"Scalability is a critical consideration as big pieces of high performing electronic skins are required to cover the relatively large surface areas of robots and prosthetic devices,\" explained Asst Prof Tee. \"ACES can be easily paired with any kind of sensor skin layers, for example, those designed to sense temperatures and humidity, to create high performance ACES-enabled electronic skin with an exceptional sense of touch that can be used for a wide range of purposes,\" he added.\r\n\r\nFor instance, pairing ACES with the transparent, self-healing and water-resistant sensor skin layer also recently developed by Asst Prof Tee\'s team, creates an electronic skin that can self-repair, like the human skin. This type of electronic skin can be used to develop more realistic prosthetic limbs that will help disabled individuals restore their sense of touch.\r\n\r\nOther potential applications include developing more intelligent robots that can perform disaster recovery tasks or take over mundane operations such as packing of items in warehouses. The NUS team is therefore looking to further apply the ACES platform on advanced robots and prosthetic devices in the next phase of their research.', 'images/post/robotics4.jpg', 'No', 0, '2019-07-28', 'Published', '2019-07-27 12:44:36', '2019-07-27 12:44:36', 3),
(15, 10, 'Robots that can sort recycling', 'CSAIL’s \"RoCycle\" system uses in-hand sensors to detect if an object is paper, metal or plastic.', 'The team’s “RoCycle” system includes a soft Teflon hand that uses tactile sensors on its fingertips to detect an object’s size and stiffness. Compatible with any robotic arm, RoCycle was found to be 85 percent accurate at detecting materials when stationary, and 63 percent accurate on an actual simulated conveyer belt. (Its most common error was identifying paper-covered metal tins as paper, which the team says would be improved by adding more sensors along the contact surface.)\r\n\r\n“Our robot’s sensorized skin provides haptic feedback that allows it to differentiate between a wide range of objects, from the rigid to the squishy,” says MIT Professor Daniela Rus, senior author on a related paper that will be presented in April at the IEEE International Conference on Soft Robotics (RoboSoft) in Seoul, South Korea. “Computer vision alone will not be able to solve the problem of giving machines human-like perception, so being able to use tactile input is of vital importance.”\r\n\r\nA collaboration with Yale University, RoCycle directly demonstrates the limits of sight-based sorting: It can reliably distinguish between two visually similar Starbucks cups, one made of paper and one made of plastic, that would give vision systems trouble.\r\n\r\nIncentivizing recycling\r\n\r\nRus says that the project is part of her larger goal to reduce the back-end cost of recycling, in order to incentivize more cities and countries to create their own programs. Today recycling centers aren’t particularly automated; their main kinds of machinery include optical sorters that use different wavelength light to distinguish between plastics, magnetic sorters that separate out iron and steel products, and aluminum sorters that use eddy currents to remove non-magnetic metals.\r\n\r\nThis is a problem for one very big reason: just last month China raised its standards for the cleanliness of recycled goods it accepts from the United States, meaning that some of the country’s single-stream recycling is now sent to landfills.\r\n\r\n\"If a system like RoCycle could be deployed on a wide scale, we\'d potentially be able to have the convenience of single-stream recycling with the lower contamination rates of multi-stream recycling,” says PhD student Lillian Chin, lead author on the new paper.\r\n\r\nIt’s surprisingly hard to develop machines that can distinguish between paper, plastic, and metal, which shows how impressive a feat it is for humans. When we pick up an object, we can immediately recognize many of its qualities even with our eyes closed, like whether it’s large and stiff or small and soft. By feeling the object and understanding how that relates to the softness of our own fingertips, we are able to learn how to handle a wide range of objects without dropping or breaking them.\r\n\r\nThis kind of intuition is tough to program into robots. Traditional hard (“rigid”) robot hands have to know an object’s exact location and size to be able to calculate a precise motion path. Soft hands made of materials like rubber are much more flexible, but have a different problem: Because they’re powered by fluidic forces, they have a balloon-like structure that can puncture quite easily.\r\n\r\nHow RoCycle works\r\n\r\nRus’ team used a motor-driven hand made of a relatively new material called “auxetics.” Most materials get narrower when pulled on, like a rubber band when you stretch it; auxetics, meanwhile, actually get wider. The MIT team took this concept and put a twist on it, quite literally: They created auxetics that, when cut, twist to either the left or right. Combining a “left-handed” and “right-handed” auxetic for each of the hand’s two large fingers makes them interlock and oppose each other’s rotation, enabling more dynamic movement. (The team calls this “handed-shearing auxetics”, or HSA.)\r\n\r\n“In contrast to soft robots, whose fluid-driven approach requires air pumps and compressors, HSA combines twisting with extension, meaning that you’re able to use regular motors,” says Chin.\r\n\r\nThe team’s gripper first uses its “strain sensor” to estimate an object’s size, and then uses its two pressure sensors to measure the force needed to grasp an object. These metrics — along with calibration data on the size and stiffnesses of objects of different material types — are what gives the gripper a sense of what material the object is made. (Since the tactile sensors are also conductive, they can detect metal by how much it changes the electrical signal.)\r\n\r\n“In other words, we estimate the size and measure the pressure difference between the current closed hand and what a normal open hand should look like,” says Chin. “We use this pressure difference and size to classify the specific object based on information about different objects that we’ve already measured.”\r\n\r\nRoCycle builds on an set of sensors that detect the radius of an object to within 30 percent accuracy, and tell the difference between “hard” and “soft” objects with 78 percent accuracy. The team’s hand is also almost completely puncture resistant: It was able to be scraped by a sharp lid and punctured by a needle more than 20 times, with minimal structural damage.\r\n\r\nAs a next step, the researchers plan to build out the system so that it can combine tactile data with actual video data from a robot’s cameras. This would allow the team to further improve its accuracy and potentially allow for even more nuanced differentiation between different kinds of materials.\r\n\r\nChin and Rus co-wrote the RoCycle paper alongside MIT postdoc Jeffrey Lipton, as well as PhD student Michelle Yuen and Professor Rebecca Kramer-Bottiglio of Yale University.', 'images/post/robotics5.JPG', 'Yes', 0, '2019-07-28', 'Published', '2019-07-27 12:52:35', '2019-07-27 12:52:35', 3),
(16, 13, 'New cause of cell aging discovered', 'Findings have huge implications for cancer and age-related health conditions', 'What causes cells to age?\r\n\r\nTo achieve this, lead author Alireza Delfarah, a graduate student in the Graham lab, focused on senescence, a natural process in which cells permanently stop creating new cells. This process is one of the key causes of age-related decline, manifesting in diseases such as arthritis, osteoporosis and heart disease.\r\n\r\n\"Senescent cells are effectively the opposite of stem cells, which have an unlimited potential for self-renewal or division,\" Delfarah said. \"Senescent cells can never divide again. It\'s an irreversible state of cell cycle arrest.\"\r\n\r\nThe research team discovered that the aging, senescent cells stopped producing a class of chemicals called nucleotides, which are the building blocks of DNA. When they took young cells and forced them to stop producing nucleotides, they became senescent, or aged.\r\n\r\n\"This means that the production of nucleotides is essential to keep cells young,\" Delfarah said. \"It also means that if we could prevent cells from losing nucleotide synthesis, the cells might age more slowly.\"\r\n\r\nGraham\'s team examined young cells that were proliferating robustly and fed them molecules labeled with stable isotopes of carbon, in order to trace how the nutrients consumed by a cell were processed into different biochemical pathways.\r\n\r\nScott Fraser and his lab worked with the research team to develop 3D imagery of the results. The images unexpectedly revealed that senescent cells often have two nuclei, and that they do not synthesize DNA.\r\n\r\nBefore now, senescence has primarily been studied in cells known as fibroblasts, the most common cells that comprised the connective tissue in animals. Graham\'s team is instead focusing on how senescence occurs in epithelial cells, the cells that line the surfaces of the organs and structures in the body and the type of cells in which most cancers arise.\r\n\r\nGraham said that senescence is most widely known as the body\'s protective barrier against cancer: When cells sustain damage that could be at risk of developing into cancer, they enter into senescence and stop proliferating so that the cancer does not develop and spread.\r\n\r\n\"Sometimes people talk about senescence as a double-edged sword, that it protects against cancer, and that\'s a good thing,\" Graham said. \"But then it also promotes aging and diseases like diabetes, cardiac dysfunction or atherosclerosis and general tissue dysfunction,\" he said.\r\n\r\nGraham said the goal was not to completely prevent senescence, because that might unleash cancer cells.\r\n\r\n\"But then on the other hand, we would like to find a way to remove senescent cells to promote healthy aging and better function,\" he said.\r\n\r\nGraham said that the team\'s research has applications in the emerging field of senolytics, the development of drugs that may be able to eliminate aging cells. He said that human clinical trials are still in early stages, but studies with mice have shown that by eliminating senescent cells, mice age better, with a more productive life span.\r\n\r\n\"They can take a mouse that\'s aging and diminishing in function, treat it with senolytic drugs to eliminate the senescent cells, and the mouse is rejuvenated. If anything, it\'s these senolytic drugs that are the fountain of youth,\" Graham said.\r\n\r\nHe added that in order for successful senolytic drugs to be designed, it was important to identify what is unique about senescent cells, so that drugs won\'t affect the normal, non-senescent cells.\r\n\r\n\"That\'s where we\'re coming in -- studying senescent cell metabolism and trying to figure out how the senescent cells are unique, so that you could design targeted therapeutics around these metabolic pathways,\" Graham said.', 'images/post/othes1.jpg', 'Yes', 3, '2019-07-28', 'Published', '2019-07-27 12:58:18', '2019-07-27 13:03:49', 3),
(17, 13, 'Scientists stimulate neurons to induce particular perceptions in mice\'s minds', 'Hallucinations are spooky and, fortunately, fairly rare. But, a new study suggests, the real question isn\'t so much why some people occasionally experience them.', 'Deisseroth, who is a Howard Hughes Medical Institute investigator and holds the D. H. Chen Professorship, pioneered optogenetics, a technology enabling researchers to stimulate particular neurons in freely moving animals with pulses of light, and to observe the resulting effects on the animals\' brain function and behavior.\r\n\r\nIn the new study, Deisseroth and his colleagues inserted a combination of two genes into large numbers of neurons in the visual cortex of lab mice. One gene encoded a light-sensitive protein that caused the neuron to fire in response to a pulse of laser light of a narrowly defined color -- in this case, in the infrared spectrum. The other gene encoded a fluorescent protein that glowed green whenever the neuron was active.\r\n\r\nThe scientists created cranial windows in the mice by removing a portion of the animals\' skulls to expose part of the visual cortex, which in both mice and humans is responsible for processing information relayed from the retina. The investigators protected this exposed area with a clear glass covering. They could then use a device they developed for the purpose of the study to project holograms -- three-dimensional configurations of targeted photons -- onto, and into, the visual cortex. These photons would land at precise spots along specific neurons. The researchers could monitor the resulting activity of nearly all individual neurons in two distinct layers of the cerebral cortex spanning about 1 square millimeter and containing on the order of several thousand neurons.\r\n\r\nWith their heads fixed in a comfortable position, the mice were shown random series of horizontal and vertical bars displayed on a screen. The researchers observed and recorded which neurons in the exposed visual cortex were preferentially activated by one or the other orientation. From these results, the scientists were able to identify dispersed populations of individual neurons that were \"tuned\" to either horizontal or vertical visual displays.\r\n\r\nThey were then able to \"play back\" these recordings in the form of holograms that produced spots of infrared light on just neurons that were responsive to horizontal, or to vertical, bars. The resulting downstream neuronal activity, even at locations relatively far from the stimulated neurons, was quite similar to that observed when the natural stimulus -- a black horizontal or vertical bar on a white background -- was displayed on the screen.\r\n\r\nThe scientists trained the mice to lick the end of a nearby tube for water when they saw a vertical bar but not when they saw a horizontal one or saw neither. Over the course of several days, as the animals\' ability to discriminate between horizontal and vertical bars improved, the scientists gradually reduced the black-white contrast to make the task progressively harder. They found that the mice\'s performance perked up if the scientists supplemented the visual displays with simultaneous optogenetic stimulation: For example, if an animal\'s performance deteriorated as a result of a lowered contrast, the investigators could boost its discrimination powers by stimulating neurons previously identified as preferentially disposed to fire in response to a horizontal or vertical bar.\r\n\r\nThis boost occurred only when the optogenetic stimulation was consistent with the visual stimulation -- for example, a vertical bar display plus stimulation of neurons previously identified as likely to fire in response to vertically oriented bars.\r\n\r\nHallucinating mice\r\n\r\nOnce the mice had become adept at discriminating between horizontal and vertical bars, the scientists were able to induce tube-licking behavior in the mice simply by projecting the \"vertical\" holographic program onto the mice\'s visual cortex. But the mice wouldn\'t lick the tube if the \"horizontal\" program was projected instead.\r\n\r\n\"Not only is the animal doing the same thing, but the brain is, too,\" Deisseroth said. \"So we know we\'re either recreating the natural perception or creating something a whole lot like it.\"\r\n\r\nIn their early experiments, the scientists had identified numerous neurons as being tuned to either a horizontal or a vertical orientation, but they hadn\'t yet directly stimulated each of those particular neurons optogenetically. Once the mice were trained, optogenetic stimulation of small numbers of these neurons was enough to get mice to respond with appropriate licking or nonlicking behavior.\r\n\r\nThe researchers were surprised to find that optogenetically stimulating about 20 neurons -- or fewer in some cases -- selected only for being responsive to the right orientation, could produce the same neuronal activity and animal behavior that displaying the vertical or horizontal bar did.\r\n\r\n\"It\'s quite remarkable how few neurons you need to specifically stimulate in an animal to generate a perception,\" Deisseroth said.\r\n\r\n\"A mouse brain has millions of neurons; a human brain has many billions,\" he said. \"If just 20 or so can create a perception, then why are we not hallucinating all the time, due to spurious random activity? Our study shows that the mammalian cortex is somehow poised to be responsive to an amazingly low number of cells without causing spurious perceptions in response to noise.\"\r\n\r\nDeisseroth is a member of Stanford Bio-X and of the Wu Tsai Neurosciences Institute at Stanford.\r\n\r\nStanford\'s Office of Technology Licensing has filed a patent application for intellectual property associated with the work.\r\n\r\nThe work was funded by the Defense Advanced Research Projects Agency, HHMI, the National Institutes of Health (grants R01MH075957 and P50DA042012), the Simons Foundation, the Wiegers Family Fund, the Nancy and James Grosfeld Foundation, the Sam and Betsy Reeves Fund, the H.L. Snyder Foundation, the Burroughs-Wellcome Foundation, the McKnight Foundation, the James S. McDonnell Foundation and the Swartz Foundation.', 'images/post/othes2.jpg', 'Yes', 4, '2019-07-28', 'Published', '2019-07-27 13:00:48', '2019-08-19 08:26:21', 3),
(19, 13, 'How Waymo is teaching self-driving cars to deal with the chaos of parking lots', 'We spoke with Waymo about training for these complex environments.', 'If you drive a car, you know that some maneuvers are harder than others. For example, an unprotected left turn—one with no green arrow to tell you when to go—will always be trickier than a standard right-hand turn. Humans aren\'t alone in those struggles. Unprotected lefts are also a challenge for cars driven by computers, and so they train for them in simulation. Autonomous car company Cruise even published a video highlighting the 1,400 left turns its vehicles tackle in San Francisco in a day.\r\n\r\nA left turn is a tricky maneuver, but the driving environment itself is also a factor in what kind of obstacles the human—or the self-driving car—might encounter. A two-lane road on a sunny day with clearly painted lines and scant traffic offers an easy landscape. But an Ikea parking lot on a Saturday afternoon? Ouch.\r\n\r\nIn fact, parking lots are a distinctive enough environment that Waymo, the self-driving car company that’s a sibling to Google, specifically trains its vehicles to deal with them by setting up real-world scenarios in a controlled environment. We spoke with Waymo engineers to learn more about how.\r\n\r\nThings can lurk near a dumpster\r\nParking lots may technically have stop signs, speed limits, and crosswalks, but drivers and pedestrians tend to do whatever they want in these environments. Shoppers carrying boxes might dart across an active driving route instead of using a crosswalk, carts can be left in the wrong place, and vehicles might drive the wrong way or over empty parking spots. “Parking lots are uniquely challenging from surface streets,” says Stephanie Villegas, who leads what Waymo calls its “structured testing” efforts. “They don’t really have standardized rules for how people should and can move about within them.”', 'images/post/self_driving.jpg', 'Yes', 1, '2019-07-19', 'Published', '2019-08-19 08:43:16', '2019-08-19 08:43:49', 3);

-- --------------------------------------------------------

--
-- Table structure for table `users`
--

CREATE TABLE `users` (
  `id` bigint(20) UNSIGNED NOT NULL,
  `name` varchar(191) COLLATE utf8mb4_unicode_ci NOT NULL,
  `email` varchar(191) COLLATE utf8mb4_unicode_ci NOT NULL,
  `email_verified_at` timestamp NULL DEFAULT NULL,
  `password` varchar(191) COLLATE utf8mb4_unicode_ci NOT NULL,
  `remember_token` varchar(100) COLLATE utf8mb4_unicode_ci DEFAULT NULL,
  `created_at` timestamp NULL DEFAULT NULL,
  `updated_at` timestamp NULL DEFAULT NULL
) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COLLATE=utf8mb4_unicode_ci;

--
-- Dumping data for table `users`
--

INSERT INTO `users` (`id`, `name`, `email`, `email_verified_at`, `password`, `remember_token`, `created_at`, `updated_at`) VALUES
(1, 'Jahid Hassan', 'jahidhassandiu91@gmail.com', NULL, '$2y$10$L34WqSNJNGFEXWS3OIkzcOV2Cw5gJvFCywApZfVIuC4bPR9vFnKtC', NULL, '2019-07-25 10:00:05', '2019-07-25 10:00:05');

--
-- Indexes for dumped tables
--

--
-- Indexes for table `authors`
--
ALTER TABLE `authors`
  ADD PRIMARY KEY (`id`);

--
-- Indexes for table `categories`
--
ALTER TABLE `categories`
  ADD PRIMARY KEY (`id`);

--
-- Indexes for table `migrations`
--
ALTER TABLE `migrations`
  ADD PRIMARY KEY (`id`);

--
-- Indexes for table `password_resets`
--
ALTER TABLE `password_resets`
  ADD KEY `password_resets_email_index` (`email`);

--
-- Indexes for table `posts`
--
ALTER TABLE `posts`
  ADD PRIMARY KEY (`id`);

--
-- Indexes for table `users`
--
ALTER TABLE `users`
  ADD PRIMARY KEY (`id`),
  ADD UNIQUE KEY `users_email_unique` (`email`);

--
-- AUTO_INCREMENT for dumped tables
--

--
-- AUTO_INCREMENT for table `authors`
--
ALTER TABLE `authors`
  MODIFY `id` bigint(20) UNSIGNED NOT NULL AUTO_INCREMENT, AUTO_INCREMENT=4;

--
-- AUTO_INCREMENT for table `categories`
--
ALTER TABLE `categories`
  MODIFY `id` bigint(20) UNSIGNED NOT NULL AUTO_INCREMENT, AUTO_INCREMENT=16;

--
-- AUTO_INCREMENT for table `migrations`
--
ALTER TABLE `migrations`
  MODIFY `id` int(10) UNSIGNED NOT NULL AUTO_INCREMENT, AUTO_INCREMENT=8;

--
-- AUTO_INCREMENT for table `posts`
--
ALTER TABLE `posts`
  MODIFY `id` bigint(20) UNSIGNED NOT NULL AUTO_INCREMENT, AUTO_INCREMENT=20;

--
-- AUTO_INCREMENT for table `users`
--
ALTER TABLE `users`
  MODIFY `id` bigint(20) UNSIGNED NOT NULL AUTO_INCREMENT, AUTO_INCREMENT=2;
COMMIT;

/*!40101 SET CHARACTER_SET_CLIENT=@OLD_CHARACTER_SET_CLIENT */;
/*!40101 SET CHARACTER_SET_RESULTS=@OLD_CHARACTER_SET_RESULTS */;
/*!40101 SET COLLATION_CONNECTION=@OLD_COLLATION_CONNECTION */;
